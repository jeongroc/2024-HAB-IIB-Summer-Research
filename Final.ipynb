{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j0q0GKOns-W"
      },
      "outputs": [],
      "source": [
        "!pip install OpenAI\n",
        "!pip install langchain --upgrade langchain\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "!pip install pypdf\n",
        "!pip install langchain_openai\n",
        "!pip install pandas\n",
        "!pip install -qU langchain-community\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI\n",
        "import tiktoken\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from langchain.llms import OpenAI\n",
        "from torch import Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from langchain.tools.json.tool import JsonSpec\n",
        "from langchain.agents.agent_toolkits import create_json_agent, JsonToolkit\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_dim, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * (-math.log(10000.0) / embedding_dim))\n",
        "        pe = torch.zeros(max_len, 1, embedding_dim)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def tea(prompt):\n",
        "    tokenized_data = encoding.encode(prompt)\n",
        "    vocab_size = encoding.n_vocab\n",
        "    embedding_dim = 768\n",
        "\n",
        "    embeddingfunction = nn.Embedding(vocab_size, embedding_dim)\n",
        "    positional_encoding = PositionalEncoding(embedding_dim)\n",
        "    multihead_attn = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=4, batch_first=True)\n",
        "    linear_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    optimizer = torch.optim.Adam(list(embeddingfunction.parameters()) +\n",
        "                                 list(multihead_attn.parameters()) +\n",
        "                                 list(linear_layer.parameters()), lr=1e-4)\n",
        "\n",
        "    checkpoint_path = 'model_checkpoint.pth'\n",
        "\n",
        "    def load_pretrained_model(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        embeddingfunction.load_state_dict(checkpoint['embeddingfunction_state_dict'])\n",
        "        multihead_attn.load_state_dict(checkpoint['multihead_attn_state_dict'])\n",
        "        linear_layer.load_state_dict(checkpoint['linear_layer_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(\"Loaded pre-trained model.\")\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        load_pretrained_model(checkpoint_path)\n",
        "        training = False\n",
        "    else:\n",
        "        training = True\n",
        "\n",
        "    if training:\n",
        "        texts = [\n",
        "            \"Please keep the x coordinates between -10 to 10 and I would like one of the x-coordinates to be as close to 5 as possible.\",\n",
        "            \"I would like to minimize the size of the building while still keeping it larger than 5 meters cubed.\",\n",
        "            \"Please change the value of one of the x-values to be as close to 0 as possible.\",\n",
        "            \"To optimize energy efficiency, adjust the HVAC settings to maintain a comfortable temperature while reducing power consumption during non-peak hours.\",\n",
        "            \"Installing LED lighting and utilizing natural daylight can reduce electricity usage in commercial buildings.\",\n",
        "            \"Enhancing insulation in the building envelope helps retain heat during the winter and keeps the building cool during the summer, leading to lower energy usage.\",\n",
        "            \"Incorporating solar panels into the building's design can provide renewable energy, reducing dependency on grid electricity and lowering energy costs.\",\n",
        "            \"An Energy Management System can monitor real-time energy usage and provide insights for optimizing energy efficiency across different building systems.\",\n",
        "        ]\n",
        "        tokenized_texts = [encoding.encode(text) for text in texts]\n",
        "\n",
        "        def train_model(tokenized_texts, epochs=100):\n",
        "            for epoch in range(epochs):\n",
        "                total_loss = 0\n",
        "                for tokens in tokenized_texts:\n",
        "                    tokens = torch.tensor(tokens).unsqueeze(0)\n",
        "                    embeddings = embeddingfunction(tokens)\n",
        "                    pos_encoded = positional_encoding(embeddings)\n",
        "                    attn_output, _ = multihead_attn(pos_encoded, pos_encoded, pos_encoded)\n",
        "                    logits = linear_layer(attn_output)\n",
        "\n",
        "                    targets = tokens.squeeze(0)[1:]\n",
        "                    logits = logits.squeeze(0)[:-1]\n",
        "\n",
        "                    loss = nn.CrossEntropyLoss()(logits.view(-1, vocab_size), targets)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss/len(tokenized_texts)}\")\n",
        "\n",
        "        train_model(tokenized_texts, epochs=100)\n",
        "\n",
        "        torch.save({\n",
        "            'embeddingfunction_state_dict': embeddingfunction.state_dict(),\n",
        "            'multihead_attn_state_dict': multihead_attn.state_dict(),\n",
        "            'linear_layer_state_dict': linear_layer.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, checkpoint_path)\n",
        "\n",
        "    tokenized_tensor = torch.tensor(tokenized_data, dtype=torch.long).unsqueeze(0)\n",
        "    embedding = embeddingfunction(tokenized_tensor)\n",
        "    encoded_tokens = positional_encoding(embedding)\n",
        "    attn_output, _ = multihead_attn(encoded_tokens, encoded_tokens, encoded_tokens)\n",
        "    logits = linear_layer(attn_output)\n",
        "    predicted_token_ids = torch.argmax(logits, dim=-1)\n",
        "    return encoding.decode(predicted_token_ids.squeeze().tolist())\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4o\")\n",
        "\n",
        "uploaded_file = \"1ZoneUncontrolled.epJSON\"\n",
        "\n",
        "with open(uploaded_file, \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "data = json.loads(content)\n",
        "spec = JsonSpec(dict_=data)\n",
        "toolkit = JsonToolkit(spec=spec)\n",
        "agent_executor = create_json_agent(llm, toolkit=toolkit, verbose=True)\n",
        "\n",
        "parameters = tea(\"Change the height of the building to 5 meters\")\n",
        "\n",
        "output = agent_executor.run(f\"You are given an epJSON file of a building with various different details and parameters. We would like you to do {parameters}.\")\n",
        "\n",
        "print(parameters)\n"
      ],
      "metadata": {
        "id": "YACU3_fonty8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_idf = '%s_%s.idf'%(file_idf_org[:-4],i)\n",
        "            command = '%s\\\\energyplus.exe -r ' %path_EP + \\\n",
        "                    '-d \"%s\\\\%s\" ' %(path_output,file_idf[:-4]) + \\\n",
        "                    '-w \"%s\" '%(file_weather) + \\\n",
        "                    '-p \"%s\" '%(file_idf[:-4]) + \\\n",
        "                    '\"%s\\\\%s\\\\%s\"' %(path_input, file_idf[:-4], file_idf)\n",
        "            print(command)\n",
        "\n",
        "            slots['process'][idx] = subprocess.Popen(command)"
      ],
      "metadata": {
        "id": "rmg8Z8U8mWU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}